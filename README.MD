# Legal Document Named Entity Recognition and Summarization

A hybrid approach combining rule-based and deep learning models for Named Entity Recognition (NER) in legal documents, with an additional document summarization feature deployed as a Streamlit web application.

## ğŸ¯ Project Overview

This project implements a sophisticated system for:
- Named Entity Recognition in legal documents using a hybrid approach
- Document summarization using state-of-the-art transformer models
- Web-based interface for easy interaction with the models

## ğŸ—ï¸ Architecture

The project consists of three main components:

1. **Hybrid NER System**
   - Rule-based NER using legal domain-specific patterns
   - Deep learning models (BiLSTM-CRF, LegalBERT)
   - Hybrid model combining both approaches

2. **Document Summarization**
   - BERT-based extractive summarization
   - T5-based abstractive summarization
   - Model evaluation and comparison

3. **Web Interface**
   - Streamlit-based web application
   - User-friendly document upload and processing
   - Visualization of results

## ğŸ“‹ Requirements

The project requires Python 3.8+ and the following dependencies:

```bash
pip install -r requirements.txt
```

## ğŸš€ Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/legal-ner-summarization.git
cd legal-ner-summarization
```

2. Create and activate a virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Download required models:
```bash
python scripts/download_models.py
```

## ğŸ’» Usage

### Running the Web Interface

```bash
streamlit run api/streamlit_summarizer.py
```

### Training Models

1. NER Models:
```bash
python models/hybrid/train.py
```

2. Summarization Models:
```bash
python summarization/bertsum_trainer.py
python summarization/t5_trainer.py
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ api/                    # Web interface and API endpoints
â”œâ”€â”€ data/                   # Dataset storage
â”œâ”€â”€ models/                 # NER models
â”‚   â”œâ”€â”€ bertsum/           # BERT-based summarization
â”‚   â”œâ”€â”€ bilstm_crf/        # BiLSTM-CRF model
â”‚   â”œâ”€â”€ hybrid/            # Hybrid NER model
â”‚   â””â”€â”€ legalbert/         # LegalBERT implementation
â”œâ”€â”€ summarization/         # Summarization models and utilities
â”œâ”€â”€ scripts/               # Utility scripts
â”œâ”€â”€ logs/                  # Training and evaluation logs
â””â”€â”€ results/               # Model outputs and evaluations
```

## ğŸ“Š Performance

The hybrid NER system achieves state-of-the-art performance on legal document datasets:
Model	               Precision	Recall	F1-Score	   Accuracy
BiLSTM-CRF	         72.3%	      78.5%	   70.3%	      75.1%
LegalBERT	         75.7%	      73.5%	   75.8%	      76.9%
Proposed Hybrid NER	92.4%	      89.8%	   91.1%	      92.5%


Summarization models performance:
- BERT-based: [0.0547]
- T5-based: [0.3225]

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- LegalBERT for pre-trained legal domain embeddings
- Hugging Face Transformers library
- Streamlit for web interface
- All contributors and maintainers

## ğŸ“§ Contact

For any questions or suggestions, please contact [kamaleswars1252k5@gmail.com]
